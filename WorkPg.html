<html>
   
   <head>
      <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
      <link rel="stylesheet" type="text/css" href="PgTemplate.css">
      <link href="https://fonts.googleapis.com/css?family=Arapey|Muli|Playfair+Display|"    rel="stylesheet">
      <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
      
    <script src="PgTemplate.js"></script>

   </head>
<body>
   <div id="about">
       <a id="name" href="index.html">VIVIAN LIU</a>
    <p id="subtitle">I designed everything on here, including the site! Click on the images to learn more about each project.</a></p>
   
   <!--   Modal exists outside of the content, main content-->
   <span id="xbutton" onclick="span_onclick()" class="close">&times;</span>
   <div id="modal">
      <div id="modalContent">
      
     
      </div>
     
   </div>
   
<div id="content">
      <div id="nav">
         
      <div id="socialmediabar">
          <a href = "https://www.linkedin.com/in/vivian-liu-1abaa7bb" ><img width="20px" class="socialmedia" src="img/linkedin.png"></a>
         <a href="https://www.behance.net/vliud6ee"><img width="20px" class="socialmedia" src="img/behance.png"></a>
      </div>
         
         
<!--      <div id="navline"> </div>-->
      
      
         
          <a class="navItems" id="aboutbutton" href="NewAbtPg.html" > About</a>
         <a class="navItems" id="work_nav" href="WorkPg.html">Work/Research</a>
         <a class="navItems" id="graphicdesign_nav" href="PlayPg.html"> Play </a>
         <a class="navItems" id="writing_nav" href="NewWritePg.html"> Writing </a> 
         
      </div>

<div class="story" id="perustory">
   <h1>Design Engineering Instructor for United Technologies for Kids</h1>
   <img src="img/peruutkall.png">
   <h3>Purpose</h3>
   In Peru, as part of the second cohort sent by the United Technologies for Kids (a Peruvian NGO), I went to Chincha, a city in the Ica province, to start a makerspace with a teaching partner (Ryan Cosner). There, at the Colegio of Santa Maria I taught a variety of design engineering concepts including Arduinos, 3D printing, soldering, and more. Every day for three weeks, I taught kids from 7th grade to 12th grade for two hours in primarily Spanish.
   <h3>Process</h3>
   Throughout the Spring 2017, I worked with a team to create an Arduino and 3D curriculum. I was tasked with leading the Arduino side, so I created a teaching plan that began with the basics of electronics and then progressed into Arduino sensing and finally Arduino actuation. I incorporated Fritzing diagrams and extended activities with LED displays and motors to help familiarize students with circuits. You can see the examples of the slides here. Their first drafts were based off of labs I had done in the fall 2016 offering of Tangible User Interfaces, a graduate class taught by professor Kimiko Ryokai and graduate student Noura Howell. I owe them a huge amount of thanks for being part of the butterfly effect that changed my life.<br><br>
   When I arrived in Peru, my days revolved around preparing for our <em>taller</em>, or workshop. My host family would drop off my partner Ryan and I at the colegio with their kids, and we would spend our mornings and early afternoons translating and editing our workshop lesson plans. We taught kids how to read engineering diagrams to create light sabers, hack their own water ionization conductivity probes, and diffuse 3 red, green, and blue LEDs under 3D-printed luminaires.<br><br>
    <button class="collapsible"></button>
          <div class="content">
   <h3>Implementation</h3>
     <img src="img/peruslides.png"><br>
  <p> 1.0 Intro to the fundamentals of programming and logic through Processing-esque code. <a href="https://docs.google.com/presentation/d/1Vxa6ecUaHeghV4o4HpQHz_HeBaj1ZIgw0E-mgl_eViE/edit?usp=sharing"> Slides here.</a><br>
   1.1 Introduction to Arduino style programming and circuits<br>
   1.2: Introduction to Arduino as input (potentiometers, the serial monitor, buttons). <a href="https://docs.google.com/presentation/d/1JPHo0VRq3P14nVNwaH65Uo0RshoZKlUdCYJl2_rN02M/edit?usp=sharing"> Slides here.</a><br>
   1.3: Circuits catch up day, electronics basics <br>
   1.4: Circuits for force-sensitive resistors, photoresistors, piezo speakers [Created a theremin]<br>
   2.0: Intro to CAD, generating excitement around 3D printing <br>
   2.1: Teaching advanced principles of CAD (patterns, lofting) <br>
   2.2: Teach Simplify 3D (the printer we brought over) and how to run it, Engineering Diagrams<br>
  2.3: Finish engineering diagrams, demo drones (we brought over a Phantom Dji 3, which allowed us to take the beautiful fireworks shot below)<br>
   3.0 Return to motor circuits<br>
   3.1 Water conductivity lab, final project brainstorming<br>
   3.2 Final project assistance <br>
   3.3 Future implications of making
     *The way the curriculum was actually executed didn't exactly follow this order tooth-and-nail, but this is a rough sketch of the content we packed into our <em>taller</em>.</p></div>
  
   <img src="img/perutheremin.png">
   <img src="img/perudrone.png">
   <img src="img/perufireworks.png">
   <img src="img/felizcumpleanos.png">
   <img src="img/peruinventory.png">
   <img src="img/perumeteaching.png">
   
   <br>
   <p> On June 7th (which happened to be my 20th birthday, we were all whisked to Lima to present at an educational fair. Our students took their projects and labwork to demonstrate their progress and meet the other freshly-minted makers across Peru (from Arequipa, Puno, Chincha, and Lima). My teaching partner and I actually spoke a few times at press conferences and at this conference as a closing speaker.</p><br>
   <p>We also go to work on <a onclick="image_onclick('mouthmouse')">an assistive technology project.</a></p>
   <h3>Reflection</h3>
   <img src="img/larcomar.png">
   <p>Teaching in Peru was a terrifying endeavor, but each and every day I am glad that when I was 19 I was daring enough hop continents and try it, because there honestly isn't a day that goes by where I don't think back to my time in South America. Sometimes I think about the taxi driver that I laughed and conversed with via Google Translate, who told me about how he used <em>Twilight</em> to learn English. Sometimes I think about the six year-old girl named Majo who played Duolingo with me. She said apple as I said <em>manzana</em>. Or the girls who invited me to kick ball with them after I ate lunch and chatted with me about animes.</p><br>
   <p>But mostly I think back to my students, who taught me how to appreciate brilliance and diversity.  Some would stay after class and listen to us teach modular arithmetic and vector math. Others worked on CAD at home, designing chess pieces and light sabers as they revelled in flexing their new creative capabilities. Everyone I met welcomed me with open arms, hearts, and minds.</p> <br>
   <p>Our students taught us about Peruvian culture as well. Two of my students moonlighted as tour guides through Chincha Baja and Chincha Alta, taking us through electronics stores, ruins, and <em>chifa</em>, the hybrid Peruvian-Chinese fare found all over Peru. My host families took me into the heart of industrial agriculture, showing me the part of Peru that is a cornucopia from which the world is fed.</p>
   <img src="img/perustudents.png">
   
      </div>
      <div class="story" id="usc_ictstory">
         <h1>Visiting Research Assistant at USC Institute of Creative Technologies</h1>
         <img src="img/uscpic.png">
         <h2>Purpose</h2>
         <p>For the latter half of the summer of 2017 (after I worked in <a onclick="image_onclick('peru')" style="color: blue">Peru</a>), I conducted research for USC, primarily doing programming tasks on an open-source Army Research Lab project called GIFT. The idea behind GIFT was to create an intelligent tutoring system to streamline army training. My contributions included developing atop the system's back-end controlled user interface and creating an interface to let users graph their gateways.</p>
         <br><br>
         <h2>Process</h2>
         <p>The beginning of my summer was spent learning how to inherit a huge code base and contribute on top of it. After I familiarized myself with the system, I began to learn how to add functionalities, make cosmetic changes, and propagate info back to the system to be logged.<br><br> <img src="img/gift1.png"><img src="img/gift2.png"></p><br><br>
         <p>I also came around to bettering my Javascript through this internship, because I developed a web tool to draw and visualize gateways as graphs. To build it, I worked with JSON, Sigma (a graphing library), and data structures such as heaps. </p><img src="img/GIFTgraphs.png">
        <br>
         <p>After adding nodes as they pleased, the users would generate a string of JSON that would be parsed by some functions I wrote. With the help of Sigma, a graph would pop up in the center layout.</p>
         <h2>Reflection</h2>
         <p>Thanks to this program, I became very adept with living in unfamiliar code. I also became more adept at back-end, learning how it can control front-end as I worked up and down the stack. Conceptually, I learned a bit about messaging concepts as well. </p><br><br>
         <p>Best of all, I got to understand an institute that was as devoted to the arts as they were to the sciences. I would watch movies with my cohort that were rendered from technologies created at the Institute (i.e. Logan, Leon: the Professional--I don't know why they chose such graphic movies) and hear from luminaries in CG like Paul Debevec. I was amazed by my fellow researchers, who would work on evolutionary neural nets or study negotiation using virtual humans. </p><br><br>   
         <img src="img/usclightstage.png"><img src="img/lastbookstore.png"><br><br>
         <p>(As an aside, I was also ecstatic to explore one of the cultural capitals of the world, Los Angeles!)</p>
         
   </div>
      <div class="story" id="first_datastory">
         <h1>Tech Intern at First Data</h1>
         <img src="img/first_data.png">
         <h2>Purpose</h2>
         <p> My first internship during college was at the Big Data branch of a company known as First Data. There, I used Python and SQL to automate data pulling and data visualization. It was an experience that really expanded my mental horizons, because I had never seen a volume of data that big before. I learned how to look at numbers like a detective, and for awhile I even would attempt it on the weekends out of sheer curiosity.</p>
         <button class="collapsible"></button>
            <div class="content">
          <p>My initial task was to aggregate data from a public source. To some degree, the team assumed that this would last me all summer. However, I learned how to interface with the API to automate that task, freeing myself to find harder and more fascinating work, of which there was plenty in Big Data. I proceeded to figure out what questions I could ask of the data I had collected and the data that I had access to. First Data's products are relevant to business growth and intelligence, so I learned what conclusions I could and could not draw from the two streams of public and corporate data I was analyzing. </p>
            </div>
         <h2>Process</h2>
         <p>My initial task was to aggregate data from a public source. To some degree, the team assumed that this would last me all summer. However, I learned how to interface with the API to automate that task, freeing myself to find harder and more fascinating work, of which there was plenty in Big Data. I proceeded to figure out what questions I could ask of the data I had collected and the data that I had access to. First Data's products are relevant to business growth and intelligence, so I learned what conclusions I could and could not draw from the two streams of public and corporate data I was analyzing. </p><br> 
         <p> After gleaning what I could from the sandbox of data before me, I also decided to flex my creative side to create an interface so that other people could input their queries and questions and be returned insights as well. Using Tableau, I created chloropleth maps, painting portraits with numbers as I aggregated data into maps as fine-grained as the zip code level. The prototype was documented, presented, and well-received by the team. </p>
         <h2>Reflection</h2>
         <p>During this experience, I got to work across the company vertical with product designers, data scientists, and product managers. Since I carved out a niche with one subset of public numbers, I also had the ability at times to sit in with some executives and guide them in understanding what affordances those numbers could give them.</p><br>
         <p>This was my first time being mentored in a company dynamic, and I was very fortunate to have been given the freedom and chance to hone such a variety of industry skills in such a short period of time.</p>
      </div>
   <div class="story" id="dystoniastory">
      <h1>Dystonia Wearable: Summer 2018 (WIP)</h1>
      <img src="img/dystonia.png" width="80%">
      
      <h2>Background</h2>
      <button class="collapsible"></button>
      <div class="content">
      <p>Blepharospasm is a focal dystonia and movement disorder where abnormal antagonistic muscle activity leads to impaired blinking. Because blepharospasm affects a person's ability to keep their eyes open, it disables people in their day-to-day functioning in activities from socialization to driving.</p>
      <p>There is neither concrete understanding of how blepharospasm originates nor is there consensus on how to diagnose it. Given the limited understanding of the disorder, diagnosis is often approached through process of elimination and excessive testing. However, as the phenotype of the disorder is setting-dependent (i.e. someone may be triggered more during conversation than during a diagnostic test), the data portrayed by diagnostic tests may be incongruent with an individual‘s outpatient experience of their disorder.</p>
      </div>
       <img src="img/dystoniasketch.png" width="80%">
      <h2>Objectives and Purpose</h2>
      <p>To understand the day-to-day impact of dystonia outside of the hospital setting, medical professions currently only have their patient’s word to rely on. Therefore, my goal this summer is to create a noninvasive and nonintrusive wearable tool to quantify dystonia outside of the hospital setting. </p>
      <p>By creating a data diary for blepharospasm, individuals can facilitate diagnosis and help doctors differentiate between blepharospasm and other disorders like myasthenia gravis and chronic progressive external opthalmoplegia. </p>
      <p>
         Blink activity would be tracked as a function of time throughout the day. The tiny no-infrared camera module, together with OpenCV, would use eye aspect ratio as a correlate for blinking. </p>
      <p>Retrospective analysis would allow individuals to identify what triggers them and what doesn’t, allowing them to do more for themselves than just to take the main line of treatment: local paralysis through injections of Botulinum toxin. </p>
      <h2>Design Engineering + Software Goals</h2>
      <ul><li>Explore a new line of tools (Utilmakers, Trotec, Raspberry Pi Zero, OpenCV) at the Invention Lab.</li>
         <li>Build a snap-fit housing for the Raspberry Pi Zero  (rPi) that supports the extended camera module at the temple tip of the glasses. </li>
         <li>Design a 3D-printable hinge that would lock tight a triangular supporting body that holds a mirror. </li>
         <li>Implement an optics trick that allows for the reflection of the eye to be caught in the visual field of the camera. By fastening the hinge with a nut and bolt, the angle of reflection could be adjusted for each individual.</li>
         <li>Establish a data pipeline from smart wearable to web interface.</li></ul>
        
         <p class="caption"> Conceptual sketching of the prototype.</p>
         <h2>Process</h2>
          <h3>Preliminary work</h3>
      
         <button class="collapsible"></button>
        
         <div class="content">
            
            <p>I began experimenting with different input modalities beginning in February 2018. Early threads of work involved Hall effect sensors, which read how local magnetic fields were altered by blinking. The caveat I found with hall effect sensors was that any motion (i.e. walking) could disturb the signal.</p> <br>
            <p>Also in February 2018, I tested out facial detection on a Raspberry Pi 3+ using tutorials provided by Adrian Roseblock from PyImageSearch and learned how eye blinking can be modeled and captured through computer vision and the eye aspect ratio.</p><br>
            <p>In June 2018, I realized that by using the Raspberry Pi Zero W, I could merge these two parallel threads of preliminary work. I began with sketches, a pair of glasses, and cardboard/paper prototyping. I received a great deal of instructive advice from Invention Lab manager Chris Myers and Mitchell Karchemsky.</p></div>
         <h3>Design Engineering Iterations</h3>
         <img src="img/cadtimeline.png" width="80%">
           <button class="collapsible"></button>
         <div class="content">
             <p>My first prints for the housing were also my first prints using the Invention Lab’s Ultimaker 2, 2+ Extended, and 3 Series printers. Because my early CADs required overhangs and support along multiple axes, I learned how to print and design with dual extrusion (PLA + breakaway material) in mind. </p><p> 
      Iteration pared down the thickness of the overhangs and points of contact in general. Six grips became 3 for an adequate snap-fit onto the glasses.</p>
      <p>An early prototype demonstrated that although the camera could capture and focus even just millimeters away from the pupil, a camera positioned right in front of the eye would be too intrusive and would obscure the entire right visual field. This led to the introduction of the angled mirror, at the advice of Chris Myers and Mitchell Karchemsky.</p></div>



         <h3>Software Iterations</h3>
      <img src="img/dystonia_softwarewip.png">
      <button class="collapsible"></button>
      <div class="content">
      <p> As I iterated upon the housing during the day, I also repeatedly iterated on the build of OpenCV on the Raspberry Pi Zero. After days of debugging the build process, the final build took well over 12 hours. Fixes required amping up the swap size on the machine, replacing one of the source files of the ffmpeg (a video library dependency), and figuring out the missing flag that was  causing an early-exit to the compilation.</p>
      <p> In July, I also began working on the data processing side, using the library matplotlib in to plot out an interactive graph as the camera (well, my webcam for now) took in the signal. The next challenges on this side involve developing on a webserver such as Rails adequate to host OpenCV and my python data post processing. Then I need to circle back to sync the design engineering side with the software side of this project.  </div>

      <h2>Results (so far)</h2>
      <img src="img/dystoniaprototype1.png">
      <h3>Lessons from the prototype</h3>
      <button class="collapsible"></button>
      <div class="content">
    <p>Experimenting with discrete and continuous readouts (i.e. Hall effect sensors vs. cameras) led to my conclusion that blinking is better tracked as a continuous signal than a discrete and binary one. This is because blinking can manifest in at a variety of “amplitudes” depending on the synergy of muscle activity that produced it and whether or not the blink was spontaneous, reflexive, or voluntary.</p>
      <p>The Raspberry Pi Zero camera runs with some lag and further work needs to investigate whether more efficient cameras (endoscope/tiny spy cameras) can be incorporated in its stead.</p>
<p>The body mounting mirror needs to be better supported against gravity, which also tends to undo the fastening mechanism fastening it all together</p>
      </div>
      <h3>Lessons from prototyping process</h3>
      <button class="collapsible"></button>
      <div class="content">
         <p>Cardboard drafts and hot glue greatly informed my CADing by giving me a 2.5D basis to measure upon.</p>
         <p>Sketching between each iteration helped clarify design flaws. I realized this when I consulted Mitchell Karchemsky about incorporating a mirror. In my initial design, I had rested the mirror parallel to the plane of the glasses lens. However, after sketching it out with Mitchell, I learned that such a straight angle would not allow eye to fall within the camera’s viewport.</p>
<p>After two years of using Type A printers and CADing without regard for the printing process, I finally realized that CADing with print orientation and support structures in mind drastically reduces chances of print failure.</p>
</div>
      <h2>Future Work</h2>
      <p> <ul><li>Stabilizing the second body that supports the mirror and optimizing the size and angle of the mirror so that when the mirror is mounted it is less noticeable to both the wearer and the observer.</li>
      <li>Finding an alternative method to fasten the two mounting (glasses/mirror) bodies at the hinge, because as of right now, the bolt currently comes loose easily. </li>
      <li>Attaching an external power source to forego wall outlets.</li>
      <li> Polishing up the Python/OpenCV postprocessing and design of the web interface.</li>
      <li>User testing (!!) to verify that the eye can stay in the range of the camera throughout the day during activities.</li>
      <li>On a complete other note...an alternate line of work to pursue would be to incorporate EEG/EMG electrodes onto these glasses. Facial electrodes are widely used during EEG and EMG procedures, though the blink signal is generally filtered out during post-processing. Like the preliminary work done using Hall-effect sensors, EEG/EMG electrodes would necessitate on-the-skin circuitry, but they could be far more reliable, easier to attach, and also yield continuous readouts. </li></ul>

</p>

         <h2>Acknowledgements</h2>
         <img src="img/sketches_chrismitchell.png">
   <p>Many thanks to: <ul><li>Invention Lab staff and friends: Chris Myers, Mitchell Karchemsky, Adam Hutz</li><li>
         My professors and mentors: Eric Paulos, Sarah Sterman</li>
      <li>My family: Haining Liu, Chun Chang, Jie Chang, Eric Liu</li></ul>

      

      




      
   </div>
   <div class="story" id="mouthmousestory">
      <h1>The Mouth/Chin-Operated Mouse</h1>
      <img src="img/mouthmouse1.png"></a>
      <h2>Purpose</h2>
      <p> When I worked in abroad during Peru, my teaching partner and I were introduced to a quadriplegic girl and asked if we could create something akin to LipSync, which is a sip-and-puff assistive tech mouse for people who can't use their limbs.</p><br><p> Though we were strapped for resources and for time, we worked on the prototype day in and day out when we weren't preparing for our workshops. What we produced within a week was a Arduino-powered mouse capable of moving and clicking as per mouth movement. </p> <br> 
      <h2>Process</h2><p> Though we had scaffolding from a previous opensource iteration (<a href="http://www.instructables.com/id/PC-Mouse-Made-With-Arduino-Uno-and-Joystick/">credit</a>), adapting the design for our user was incredibly challenging. All we had were the electronics, drone equipment, and two 3D printers that we had brought over. We began by hacking apart a drone remote controller, because we needed its joystick. After that, my partner and I partitioned the tasks so that I would handle the software and circuits and he would handle the physical making. He came up with a clever way to instigate pressure on the force sensitive resistor: through a mini pressure chamber created by the close of the mouth over an 3D printed orifice.<br></p><p>In parallel, I worked on the Java that would allow the Arduino input to take over the computer's mouse. This was taxing, because I had not seen Java or Intellij in a while, was unfamiliar coding on a PC, and was without consistent access to Internet/Stack Overflow to remedy this.</p><br>
      <p>As I acclimated to my new developer environment, I wrangled with the bugs in the opensource code and experimented with types of interaction. After finally debugging all the bugs in the open source code by rewriting large chunks of it for the particular PC I worked on, I explored speech commands while my partner worked on pressure-chamber-enabled clicks. My method was to parse the cluck of a tongue into a left click, making for a more hygenic and easy interaction. However, this hope was dashed when we realized that there would be simply too much irrelevant positive feedback.
      </p><br><p>The pressure chamber had a slit through which the head of a force sensitive resistor could fit through. When the air filled the chamber in, it read a value that we normalized for. The lips would cover the cone of the chamber so that any tilt would lead translate to action on the computer screen. And when the air was sucked out, we produced a click.</p><br>
      <p>The housing and chamber were completely 3D printed, and we enlisted our students to help us during the CAD design process so that they could apply their new skills.</p><br> Though we made it as far as a high-fidelity prototype, the mouse in the end did not perform consistently enough for everyday use.
      <h2>Reflection</h2>
      <p>Out of every project that I had ever done, this project was the most humbling. I am cautious by nature, and I was not sure that I could handle teaching on top of this project, which was aligned with UTK's social impact mission. There was more riding on this project than just a grade, like how it is in college. Even more than that, there was a person who needed it and who wanted it. I applied myself with 200 percent, and learned a lot of lessons along the way.</p><br>
      <p> The greatest lesson that it taught me was that users must be included in the design process. When I watched the girl we had made this prototype for struggle with our device, all the pride I had built up from the engineering feat I had pulled all-nighter after all-nighter for waned fast. UX was right--question first before you create the solutions.</p><br>
      <p> When I came back to the States, I was so disappointed that I couldn't finish the project that I restarted it when fall semester at Berkeley rolled around by myself. I worked on a chin-operated mouse this time, which made for a more sanitary option than a mouth one. Other improvements included a dexterous joystick and a mounted button at the top of the rod, which made for easy clicking at the simple push of the head.</p><br>
      <img style="width: 534px;" src="img/mouthmouse.png">
      <img src="img/mouthmouse2.png">
           <br>
   <p> By the time I had completed this iteration though, the girl had already gotten a LipSync alternative from Hong Kong. She's really happy with it, and that's all that I can ask for.</p>
   
   </div>
      <div class="story" id="webteachstory">
         <h1>STEAM Workshops at East Bay School for Boys<br> and Fremont Main Library</h1>
         <h2>Purpose</h2>
         <p> Something I wanted to encourage within the community I grew up within was the notion that art and science don't have to exist in a dichotomy. There are so many ways to strike synergy between the two domains, and I wanted to give back during my sophomore year. </p><br><br> 
         <p>This was how I began a series of workshops which taught kids anywhere from five to seventeen the beauty of: generating fractals as art, coding optical illusions, building a minimalist Mario game, web animation</p>

         <img src="img/steam1.png">
         <img src="img/steam2.png">
         <img src="img/steam3.png"><br><br>
         <img src="img/steam4.png">
         <img src="img/steam5.png">
         <img src="img/steam6.png"><br><br>
         <h2>Process</h2>
         <p> In high school, I had volunteered for a program called Science for Youth at my local library. In college, I reached out to the same coordinators and asked if I could volunteer again and hold free workshops revolving around creative computing.</p><br><br>
         <p>What began at Fremont Main Library eventually carried over to a few workshops at East Bay School for Boys, a school neighboring Berkeley that I had conducted field work at during Spring 2017.</p> <br><br>
         <h2>Reflection</h2>
         <p> Each workshop lasted a hectic 1.5 hours, during which I juggled teaching and helping kids debug. However, there really is nothing more amazing than hearing a student exclaim to their parent, "That was amazing!" My efforts in teaching creative computing helped students discover a little more about their world and realize that they each have the innate ability to craft it as well.</p> <br><br>
         <p>You can see some of my presentations <a href="https://docs.google.com/presentation/d/1DBuR4GVNwb3eIOLwtUgis5PM9IWDc7H11lGQqIHH3Sk/edit?usp=sharing">here (Mario)</a> and <a href="https://docs.google.com/presentation/d/1AaxmRzOFWOuL6-emED2kd8sqc8dIfC3co7dtZxv47BY/edit?usp=sharing"> here </a>.</p><br><br>
         <img src="img/steamfractal.png">
      </div>
      <div class="story" id="visualstylestory">
         <h1>Research Assistant at Hybrid Ecologies Lab</h1>
         <img src="img/literairy0.png">
         <h2>Purpose</h2>
         <p>Beginning of 2017, I worked with PhD student Sarah Sterman and undergraduate Evey Huang in an endeavor to create a human-computer interaction system dedicated to literature. Specifically, we wanted to computationally model prose style and teach a machine stylometry. What is stylometry? An apt, instructive example of the style spectrum would be to compare Hemingway's terse minimalism with Dickens' or Hugo's 19th century verboseness.</p><br>
         <h2> Process</h2>
           <p> Sarah began working on this project in a graduate course we both took taught by professor Abigail de Kosnik, Making Sense of Cultural Data. Through the course, we were introduced to a spate of digital humanities tools (network analysis, web scraping, the works) that allowed us to model the mind of society/culture.</p> <br>
            <p>After the course, I hopped aboard Sarah's project as she brought it outside of the classroom and into realm of HCI research. We first began with literature review of natural language processing and the closest cousin to our stylometry question--authorship analysis. Then we conducted user studies, trying to gauge if style was something that could be universally characterized.</p><br>
         <p>Throughout Spring 2017, I began building a natural language feature analyzer using SpaCy, an NLP library. I vacillated finding new features and implementing them. I wrote and tested functions for everything from conventional part of speech tagging to unigram and bigram processing to hapax legomena (vocabulary richness). I spent three-day weekends thinking of how to architect the machine to not just read but gain an intuition based upon literary theory. To give you an idea of how diverse writing can be, take a look at this figure from the paper we submitted.</p><br><img src="img/literairyfig.png">
         <p>Because we were encroaching on the domain of machine learning, I also explored support vector machines, using them to tackle the example I posed above by comparing a toy data set of excerpts derived from <em> Les Miserables</em> and <em>The Sun Also Rises</em></p><br>
         <p> After a break during the summer working in <a onclick="image_onclick('peru')">Peru</a> and <a onclick="image_onclick('usc_ict')">USC Institute of Creative Tech</a>, I came back to the project during the fall. During this time, I worked on engineering the interface as we geared towards the DIS 2018 submission deadline using Javascript, d3.js, and Ruby on Rails.</p><br>
         <p>  At this time, I started working on the 'visual' part of our Visual Style project. We wanted to see if we could create a standard way to visualize our texts to represent how similar their stylistic footprints were. There was a lot of early exploration.</p><br>
         <img src="img/literairy2.png"> <br><br>
         <img src="img/literairy.png"><br>
         <p>By the end of fall, our pipeline looked like this, and we began conducting user studies by interviewing writers and other people interested in creativity support tools. We wrapped up our the first phase of our study as 2017 winded down.</p>
         <img src="img/literairyfig2.png">
         <h2>Reflection</h2>
         <p>Working with the researchers at Hybrid Ecologies was incredible--I used to describe it as people in a lab of people dedicated to mad science. Every project was eccentric, and Visual Style certainly was as well.</p><br>
         <p>Sarah was a great mentor, who was always receptive to my input. I was allowed to be apart of the experimental design process, which forced me to critically think not just about the data but how I would collect it. Every week, I realized that I was working with Sarah on a problem few had ever tackled before. You could say that Hybrid Ecologies truly taught me to understand the spirit of research.</p><br>
         <p> Working on this project also taught me that I have the capacity to learn everything. I would have never expected to touch support vector machines or unsupervised self organizing maps or any of the other concepts and techniques I wrangled with that spring otherwise.</p><br>
         <p>Working on the project also obviously gave me a grander purview of literature, both in the academic and traditional sense. I relaxed between discrete problem sets searching, cleaning, and reading great literature. I went to sleep with research about advances in machines learning style.</p><br>
         <p>For how it grew me as a writer, researcher, and a scientist, I will always be grateful.</p>
         
         
            
            

       
      </div>
      <div class="story" id="socialbutterflystory">
         <h1> Social Butterfly</h1>
         
         <img class="addendumImg" src="img/butterflyandme.png">
         <em style="margin: 0 auto"> Nominated/pending for publication in <strong>Made in Berkeley</strong></em>
         <em><a href="https://www.youtube.com/playlist?list=PLbok9t2URfW2KXDP0DzB2gbUNEDPEUn3p&disable_polymer=true">Link to our video about the Social Butterfly</a></em><br>
         <h2>Purpose</h2>
         
         <br>
         Social Butterfly was the collaborative effort of me, Justine Chia, Varna Vasudevan, and Yuki Zhan for Spring 2018's offering of Critical Making. <br> <br> Our intention was to create wearable wings for the purpose of activity-based socialization amongst children. Wings are playful, confident, and larger-than-life, and we wanted to create a prototype that could reflect that positive change within a wearer. Our wings had a toggle that could trigger motor-actuated fluttering motion to attract the attention of nearby playmates. <br><br>They also incorporated six acrylic panels that children could customize. By drawing or etching tokens of what they love upon them, wearers could hold their personalized ice breakers close. When the panels were tapped upon, they would illuminate from capacitative touch.<br>
         <br><img src="img/butterflylit.png"><img src="img/butterflylit2.png"><br><br>
         These wings were meant to foster conversation and celebrate creativity. We were incredibly fortunate to have our design process guided by the expertise of Invention Lab managers and supervisors Chris Myers, Kuan-Ju Wu, and Mitchell Karchemsky.
         <br>
         <h2>Process</h2>
         As we were challenged to create a cosmetic computing wearable for our last class provocation, we began by affinity mapping our concept of wearables and the types of technologies we felt like exploring. We were entranced by things as extravagant as iconic Victoria Secret wings to things as everyday as backlit LED word clocks. Initially, our wearable careened towards the theme of self-esteem and body positive, which is reflected in some of our first lo-fi prototypes.<br><br>
         <img src="img/butterflyconcept.png">
      
         After some cross-critiquing and hands-on exploration, we pivoted away from some of  the concepts we originally toyed with: projections, mechanical hinges, words as display content, and static wings. We decided instead on two interactions: capacitative touch illumination and living hinges for flexible flapping. 
      We set the following goals for our prototype:<br>
         <ul><li>Foster Communication</li>
            <li>Encourage Social Conversation</li>
            <li>Attract the Attention of Nearby Playmates</li>
            <li>Personalizable Aspect of the Overall Design</li>
         </ul><br>
         Chris Myers helped immensely with the two-state fluttering mechanism by brainstorming, sketching, and rapid prototyping with us. We first created an iteration of the mechanism by changing the tension of rope with a motor. By appending living hinges to the ends of the rope, we realized we could simulate fluttering.
         <img src="img/butterflychris.png"><br><br>
         <img src="img/butterflyflutter.png">
         <h2>Technical Implementation</h2>
         To implement our goals, we needed a motor circuit and a capacitative touch circuit. We drove a motor using the analog read of a potentiometer. Our capacitative touch circuit registered touch and would swap illumination once another online panel was touched. <br>
         <h2>Reflection</h2>
         Major challenges in our design were creating something lightweight enough to be worn, fastening a circuit vertically so that it could defy gravity, and creating just the right amount of force to pull the living hinge back without damaging its integrity. <br><br>
         <img src="img/butterflycircuit.png">
         <img src="img/butterflyprocess.png"><img src="img/butterflyprocess1.png"><br><br>
       
         The craft, technology, art, confidence, and personality expressed by this unconventional wearable fit the balance of hacking culture, crafts, and technology that was at the core of Critical Making. 

         
   </div>
     
    

   
   <div id="mainContent"> 

      
      <div id="sidebars">
         
          <div class="dropdown">
         
        <button class="dropbtn">Dropdown</button>
        <div class="dropdown-content">
<!--           <a href="#" onclick="selection_onclick('container')" >See All</a>-->
          <a href="#" onclick="selection_onclick('ResearchIntern')" >Research/Internships</a>
    
          <a href="#" onclick="selection_onclick('Prototypes')">Prototypes</a>
          <a href="#" onclick="selection_onclick('Teaching')">Teaching</a>
           <a href="#" onclick="selection_onclick('Misc')">Misc</a>
        </div>
             
             <button class="dropbtn" onclick="selection_onclick('container')" id="seeall">See All</button>
      </div>
<!--         LEFT SIDEBAR BEGIN-->
         <div class="sidebar" id="leftSidebar">
            
            <div class="container ResearchIntern">
               <div class="overlay">
               <img onclick="image_onclick('dystonia')" class="projImg" id="dystonia" src="img/dystonia.png">
                 <div class="middle">
                <div class="text"><p class="projText"> Dystonia Wearable</p></div>
                 </div>
              </div>
            </div>
            
            <div class="container ResearchIntern">
               <div class="overlay">
               <img onclick="image_onclick('usc_ict')" class="projImg" id="usc_ict" src="img/usc_ict.png">
                 <div class="middle">
                <div class="text"><p class="projText">Research Assistant, USC Institute of Creative Tech</p></div>
                 </div>
              </div>
            </div>
            
          
            <div class="container Teaching">
               <div class="overlay">
               <img onclick="image_onclick('webteach')" class="projImg" id="webteach" src="img/webteach.png">
                 <div class="middle">
                <div class="text"><p class="projText">STEAM Workshops</p></div>
                 </div>
              </div>
            </div>
            
            
         
<!--      LEFT SIDEBAR END-->
         </div>
         
         
<!--         CENTER SIDEBAR-->
         <div class="sidebar" id="CenterSidebar">
         
            
             <div class="container teaching">
               <div class="overlay">
               <img onclick="image_onclick('peru')" class="projImg" id="peru" src="img/peru.png">
                 <div class="middle">
                <div class="text"><p class="projText"> United Tech for Kids, NGO Work in Peru</p></div>
                 </div>
              </div>
            </div>
            
            <div class="container Prototypes">
               <div class="overlay">
               <img onclick="image_onclick('mouthmouse')" class="projImg" id="mouthmouse" src="img/mouthmouse.png">
                 <div class="middle">
                <div class="text"><p class="projText">Chin-operated mouse: assistive tech</p></div>
                 </div>
              </div>
            </div>
    <div class="container ResearchIntern">
               <div class="overlay">
               <img onclick="image_onclick('first_data')" class="projImg" id="first_data" src="img/first_data.png">
                 <div class="middle">
                <div class="text"><p class="projText">Data Intern, First Data</p></div>
                 </div>
              </div>
            </div>
<!--dystonia glasses           -->
<!--            girls in engineering -->
            
<!--CENTER SIDEBAR END-->
            </div>
         
         
<!--         RIGHT SIDEBAR-->

                  <div class="sidebar" id="rightSidebar">
                   <div class="container ResearchIntern">
                     <div class="overlay">
                     <img onclick="image_onclick('visualstyle')" class="projImg" id="visualstyle" src="img/visualstyle.png">
                       <div class="middle">
                      <div class="text"><p class="projText">Hybrid Ecologies Lab</p></div>
                       </div>
                    </div>
                  </div>


               <div class="container Prototypes">
                     <div class="overlay">
                     <img onclick="image_onclick('socialbutterfly')" class="projImg" id="socialbutterfly" src="img/butterflysmaller.png">
                       <div class="middle">
                      <div class="text"><p class="projText">Social Butterfly (Team Project) </p>                  </div>
                       </div>
                    </div>
               </div>
                     
            <div class="container Teaching">
            <div class="overlay">
                     <img onclick="image_onclick('hand')" class="projImg" id="hand" src="img/hand">
                       <div class="middle">
                      <div class="text"><p class="projText">Girls In Engineering Volunteer: Open Prosthetics</p>                  </div>
                       </div>
               </div></div>
<!--RIGHT SIDEBAR END-->
             </div>
<!--         SIDEBAR ENDS-->
         </div>
<!--      Script for collapsible must be in body-->
    <script>
           
               var coll = document.getElementsByClassName("collapsible");
               var i;

               for (i = 0; i < coll.length; i++) {
                 coll[i].addEventListener("click", function() {
                   this.classList.toggle("active");
                   var content = this.nextElementSibling;
                 
                   if (content.style.display === "block") {
                     content.style.display = "none";
                   } else {
                     content.style.display = "block";
                    
                   }
                 });
               }
            </script>
     
   </div>
   </div>
      

      
      
     
       
</body>
</html>           
      
    